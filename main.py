import re
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from googleapiclient.discovery import build
from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer
from deep_translator import GoogleTranslator
import sys
import os
from urllib.parse import urlparse, parse_qs
from dotenv import load_dotenv

# –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è –∑–º—ñ–Ω–Ω–∏—Ö —Å–µ—Ä–µ–¥–æ–≤–∏—â–∞
load_dotenv()

# --- –ù–ê–õ–ê–®–¢–£–í–ê–ù–ù–Ø ---
API_KEY = os.getenv('YOUTUBE_API_KEY')
MAX_RESULTS = 50  # –ö—ñ–ª—å–∫—ñ—Å—Ç—å –∫–æ–º–µ–Ω—Ç–∞—Ä—ñ–≤ –¥–ª—è –∞–Ω–∞–ª—ñ–∑—É

# –Ü–Ω—ñ—Ü—ñ–∞–ª—ñ–∑–∞—Ü—ñ—è —ñ–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç—ñ–≤
analyzer = SentimentIntensityAnalyzer()
translator = GoogleTranslator(source='auto', target='en')


# --- –§–£–ù–ö–¶–Ü–á ---

def extract_video_id(url):
    """
    –í–∏—Ç—è–≥—É—î YouTube ID –∑ —Ä—ñ–∑–Ω–∏—Ö —Ñ–æ—Ä–º–∞—Ç—ñ–≤ –ø–æ—Å–∏–ª–∞–Ω—å.
    –ü—ñ–¥—Ç—Ä–∏–º—É—î:
    - https://www.youtube.com/watch?v=ID
    - https://youtu.be/ID
    - https://www.youtube.com/shorts/ID
    - –ü—Ä–æ—Å—Ç–æ ID (—è–∫—â–æ –∫–æ—Ä–∏—Å—Ç—É–≤–∞—á –≤–≤—ñ–≤ —Ç—ñ–ª—å–∫–∏ –π–æ–≥–æ)
    """
    # –Ø–∫—â–æ —Ü–µ —Å—Ö–æ–∂–µ –Ω–∞ —á–∏—Å—Ç–∏–π ID (11 —Å–∏–º–≤–æ–ª—ñ–≤, –±–µ–∑ –ø—Ä–æ–±—ñ–ª—ñ–≤), –ø–æ–≤–µ—Ä—Ç–∞—î–º–æ —è–∫ —î
    if len(url) == 11 and ' ' not in url and '/' not in url:
        return url

    query = urlparse(url)

    # –í–∏–ø–∞–¥–æ–∫ 1: youtu.be/ID
    if query.hostname == 'youtu.be':
        return query.path[1:]

    # –í–∏–ø–∞–¥–æ–∫ 2: youtube.com/watch?v=ID –∞–±–æ youtube.com/shorts/ID
    if query.hostname in ('www.youtube.com', 'youtube.com', 'm.youtube.com'):
        if query.path == '/watch':
            p = parse_qs(query.query)
            return p['v'][0]
        if query.path[:7] == '/embed/':
            return query.path.split('/')[2]
        if query.path[:3] == '/v/':
            return query.path.split('/')[2]
        if query.path[:8] == '/shorts/':  # –ü—ñ–¥—Ç—Ä–∏–º–∫–∞ Shorts
            return query.path.split('/')[2]

    # –Ø–∫—â–æ –Ω—ñ—á–æ–≥–æ –Ω–µ —Å–ø—Ä–∞—Ü—é–≤–∞–ª–æ, –ø–æ–≤–µ—Ä—Ç–∞—î–º–æ None
    return None


def clean_text(text):
    """–ü—Ä–∏–±–∏—Ä–∞—î –∑–∞–π–≤—ñ –ø—Ä–æ–±—ñ–ª–∏ –º—ñ–∂ –ª—ñ—Ç–µ—Ä–∞–º–∏ (T O P -> TOP)"""
    return re.sub(r'(?<=\b\w)\s+(?=\w\b)', '', text)


def analyze_comment(text):
    """–ü–µ—Ä–µ–∫–ª–∞–¥ + –ê–Ω–∞–ª—ñ–∑ –µ–º–æ—Ü—ñ–π"""
    try:
        translated = translator.translate(text)
    except:
        translated = text

    if not translated:
        translated = text

    final_text = clean_text(translated)
    scores = analyzer.polarity_scores(final_text)
    compound = scores['compound']

    if compound >= 0.05:
        category = 'Positive'
    elif compound <= -0.05:
        category = 'Negative'
    else:
        category = 'Neutral'

    return compound, category, final_text


def get_data(video_id, api_key, max_results):
    try:
        youtube = build('youtube', 'v3', developerKey=api_key)
    except Exception as e:
        print(f"\n–ü–æ–º–∏–ª–∫–∞ –ø—ñ–¥–∫–ª—é—á–µ–Ω–Ω—è –¥–æ API: {e}")
        return None

    data = []
    print(f"üì• –ó–∞–≤–∞–Ω—Ç–∞–∂—É—é –∫–æ–º–µ–Ω—Ç–∞—Ä—ñ –¥–ª—è –≤—ñ–¥–µ–æ ID: {video_id}...")

    try:
        request = youtube.commentThreads().list(
            part="snippet", videoId=video_id, maxResults=max_results, textFormat="plainText"
        )
        response = request.execute()

        total = len(response['items'])
        print(f"üîÑ –ü–æ—á–∞—Ç–æ–∫ –æ–±—Ä–æ–±–∫–∏ {total} –∫–æ–º–µ–Ω—Ç–∞—Ä—ñ–≤...")

        for i, item in enumerate(response['items']):
            snippet = item['snippet']['topLevelComment']['snippet']
            original_text = snippet['textDisplay']
            author = snippet['authorDisplayName']

            score, category, translated_text = analyze_comment(original_text)

            data.append({
                'Author': author,
                'Original': original_text,
                'Translated': translated_text,
                'Score': score,
                'Category': category
            })

            # –í–∏–≤–æ–¥–∏–º–æ –ø—Ä–æ–≥—Ä–µ—Å —É –∫–æ–Ω—Å–æ–ª—å
            print(f"üîÑ –û–±—Ä–æ–±–ª–µ–Ω–æ: {i + 1}/{total}", end='\r')

        print("\n‚úÖ –û–±—Ä–æ–±–∫—É –∑–∞–≤–µ—Ä—à–µ–Ω–æ!")
        return pd.DataFrame(data)

    except Exception as e:
        print(f"\n–ü–æ–º–∏–ª–∫–∞ –ø—Ä–∏ –æ—Ç—Ä–∏–º–∞–Ω–Ω—ñ –¥–∞–Ω–∏—Ö (–º–æ–∂–ª–∏–≤–æ, –Ω–µ–∫–æ—Ä–µ–∫—Ç–Ω–∏–π ID –∞–±–æ –∑–∞–∫—Ä–∏—Ç—ñ –∫–æ–º–µ–Ω—Ç–∞—Ä—ñ): {e}")
        return None


def show_report(df, video_id):
    avg_score = df['Score'].mean()
    total = len(df)
    pos_count = len(df[df['Category'] == 'Positive'])
    neg_count = len(df[df['Category'] == 'Negative'])
    neu_count = len(df[df['Category'] == 'Neutral'])

    if avg_score > 0.1:
        verdict = "üëç –ü–æ–∑–∏—Ç–∏–≤–Ω–∏–π"
    elif avg_score < -0.1:
        verdict = "üëé –ù–µ–≥–∞—Ç–∏–≤–Ω–∏–π"
    else:
        verdict = "üòê –ù–µ–π—Ç—Ä–∞–ª—å–Ω–∏–π/–ó–º—ñ—à–∞–Ω–∏–π"

    print("\n" + "=" * 60)
    print(f"üìä –ó–ê–ì–ê–õ–¨–ù–ò–ô –ó–í–Ü–¢")
    print("=" * 60)
    print(f"üîπ –í—Å—å–æ–≥–æ –∫–æ–º–µ–Ω—Ç–∞—Ä—ñ–≤: {total}")
    print(f"üîπ –°–µ—Ä–µ–¥–Ω—ñ–π —Ä–µ–π—Ç–∏–Ω–≥:  {avg_score:.4f} (–≤—ñ–¥ -1 –¥–æ 1)")
    print(f"üîπ –í–µ—Ä–¥–∏–∫—Ç –∞—É–¥–∏—Ç–æ—Ä—ñ—ó: {verdict}")
    print("-" * 30)
    print(f"üíö –ü–æ–∑–∏—Ç–∏–≤–Ω–∏—Ö: {pos_count} ({pos_count / total * 100:.1f}%)")
    print(f"‚ù§Ô∏è –ù–µ–≥–∞—Ç–∏–≤–Ω–∏—Ö: {neg_count} ({neg_count / total * 100:.1f}%)")
    print(f"‚ö™ –ù–µ–π—Ç—Ä–∞–ª—å–Ω–∏—Ö: {neu_count} ({neu_count / total * 100:.1f}%)")
    print("=" * 60)

    df_sorted = df.sort_values(by='Score', ascending=False)

    print("\nüèÜ –¢–û–ü-5 –ù–ê–ô–î–û–ë–†–Ü–®–ò–• –ö–û–ú–ï–ù–¢–ê–†–Ü–í:")
    for i, row in df_sorted.head(5).iterrows():
        clean_comment = row['Original'][:80].replace('\n', ' ')
        print(f"  [{row['Score']:.2f}] {row['Author']}: {clean_comment}...")

    print("\nü§¨ –¢–û–ü-5 –ù–ê–ô–ó–õ–Ü–®–ò–• –ö–û–ú–ï–ù–¢–ê–†–Ü–í:")
    for i, row in df_sorted.tail(5).iterrows():
        clean_comment = row['Original'][:80].replace('\n', ' ')
        print(f"  [{row['Score']:.2f}] {row['Author']}: {clean_comment}...")

    print("\n" + "=" * 60)

    # –ì—Ä–∞—Ñ—ñ–∫–∏
    sns.set_style("whitegrid")
    fig, axes = plt.subplots(1, 2, figsize=(15, 6))
    fig.suptitle(f'–ê–Ω–∞–ª—ñ–∑ –Ω–∞—Å—Ç—Ä–æ—é –∞—É–¥–∏—Ç–æ—Ä—ñ—ó (ID: {video_id})', fontsize=16)

    counts = df['Category'].value_counts()
    colors = {'Positive': '#66bb6a', 'Neutral': '#fff176', 'Negative': '#ef5350'}
    pie_colors = [colors.get(k, '#bdbdbd') for k in counts.index]

    if len(counts) > 0:
        axes[0].pie(counts, labels=counts.index, autopct='%1.1f%%', startangle=140,
                    colors=pie_colors, explode=[0.05] * len(counts))
    axes[0].set_title('–ß–∞—Å—Ç–∫–∏ –µ–º–æ—Ü—ñ–π')

    sns.histplot(df['Score'], bins=20, kde=True, ax=axes[1], color='#5c6bc0')
    axes[1].set_title('–†–æ–∑–ø–æ–¥—ñ–ª –æ—Ü—ñ–Ω–æ–∫')
    axes[1].set_xlabel('–ù–µ–≥–∞—Ç–∏–≤ (-1) <----> –ü–æ–∑–∏—Ç–∏–≤ (+1)')
    axes[1].axvline(0, color='black', linestyle='--', linewidth=1)

    plt.tight_layout()
    plt.show()


# --- –ì–û–õ–û–í–ù–ò–ô –ë–õ–û–ö ---
if __name__ == "__main__":
    if not API_KEY:
        print(" –ü–æ–º–∏–ª–∫–∞: –ù–µ –∑–Ω–∞–π–¥–µ–Ω–æ API –∫–ª—é—á! –ü–µ—Ä–µ–≤—ñ—Ä—Ç–µ —Ñ–∞–π–ª .env")
        sys.exit()

    # –ó–∞–ø–∏—Ç –ø–æ—Å–∏–ª–∞–Ω–Ω—è —É –∫–æ—Ä–∏—Å—Ç—É–≤–∞—á–∞
    url_input = input("üîó –í—Å—Ç–∞–≤—Ç–µ –ø–æ—Å–∏–ª–∞–Ω–Ω—è –Ω–∞ –≤—ñ–¥–µ–æ YouTube (–∞–±–æ –ø—Ä–æ—Å—Ç–æ ID): ").strip()

    # –í–∏—Ç—è–≥—É–≤–∞–Ω–Ω—è ID
    video_id = extract_video_id(url_input)

    if video_id:
        df = get_data(video_id, API_KEY, MAX_RESULTS)

        if df is not None:
            show_report(df, video_id)
            # –ó–±–µ—Ä–µ–∂–µ–Ω–Ω—è
            filename = f"report_{video_id}.csv"
            df.to_csv(filename, index=False, encoding='utf-8-sig')
            print(f"\nüíæ –î–∞–Ω—ñ –∑–±–µ—Ä–µ–∂–µ–Ω–æ —É —Ñ–∞–π–ª '{filename}'")
    else:
        print("–ù–µ –≤–¥–∞–ª–æ—Å—è —Ä–æ–∑–ø—ñ–∑–Ω–∞—Ç–∏ –∫–æ—Ä–µ–∫—Ç–Ω–µ –ø–æ—Å–∏–ª–∞–Ω–Ω—è –Ω–∞ YouTube.")